{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4a1bdb1e8e7f0f8e",
   "metadata": {},
   "source": [
    "# Advanced Data Mining\n",
    "\n",
    "## Data preprocessing\n",
    "\n",
    "### Reducing dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ba42364-d673-4860-a331-fb4c6c553c69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARNING: The directory '/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
      "\u001b[0mDefaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: kmedoids==0.5.3.1 in /.local/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (0.5.3.1)\n",
      "Requirement already satisfied: matplotlib==3.9.1 in /usr/local/lib/python3.11/dist-packages (from -r requirements.txt (line 2)) (3.9.1)\n",
      "Requirement already satisfied: nltk==3.9.1 in /.local/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (3.9.1)\n",
      "Requirement already satisfied: pandas==2.2.3 in /.local/lib/python3.11/site-packages (from -r requirements.txt (line 4)) (2.2.3)\n",
      "Requirement already satisfied: psycopg2-binary==2.9.10 in /.local/lib/python3.11/site-packages (from -r requirements.txt (line 5)) (2.9.10)\n",
      "Requirement already satisfied: scikit-learn==1.6.0 in /.local/lib/python3.11/site-packages (from -r requirements.txt (line 6)) (1.6.0)\n",
      "Requirement already satisfied: seaborn==0.13.2 in /.local/lib/python3.11/site-packages (from -r requirements.txt (line 7)) (0.13.2)\n",
      "Requirement already satisfied: SQLAlchemy==2.0.36 in /.local/lib/python3.11/site-packages (from -r requirements.txt (line 8)) (2.0.36)\n",
      "Requirement already satisfied: tqdm==4.67.1 in /.local/lib/python3.11/site-packages (from -r requirements.txt (line 9)) (4.67.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.1->-r requirements.txt (line 2)) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.1->-r requirements.txt (line 2)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.1->-r requirements.txt (line 2)) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.1->-r requirements.txt (line 2)) (1.4.5)\n",
      "Requirement already satisfied: numpy>=1.23 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.1->-r requirements.txt (line 2)) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.1->-r requirements.txt (line 2)) (24.1)\n",
      "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.1->-r requirements.txt (line 2)) (10.4.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /usr/lib/python3/dist-packages (from matplotlib==3.9.1->-r requirements.txt (line 2)) (2.4.7)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib==3.9.1->-r requirements.txt (line 2)) (2.9.0.post0)\n",
      "Requirement already satisfied: click in /.local/lib/python3.11/site-packages (from nltk==3.9.1->-r requirements.txt (line 3)) (8.1.7)\n",
      "Requirement already satisfied: joblib in /.local/lib/python3.11/site-packages (from nltk==3.9.1->-r requirements.txt (line 3)) (1.4.2)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /.local/lib/python3.11/site-packages (from nltk==3.9.1->-r requirements.txt (line 3)) (2024.11.6)\n",
      "Requirement already satisfied: pytz>=2020.1 in /.local/lib/python3.11/site-packages (from pandas==2.2.3->-r requirements.txt (line 4)) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /.local/lib/python3.11/site-packages (from pandas==2.2.3->-r requirements.txt (line 4)) (2024.2)\n",
      "Requirement already satisfied: scipy>=1.6.0 in /.local/lib/python3.11/site-packages (from scikit-learn==1.6.0->-r requirements.txt (line 6)) (1.14.1)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in /.local/lib/python3.11/site-packages (from scikit-learn==1.6.0->-r requirements.txt (line 6)) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy==2.0.36->-r requirements.txt (line 8)) (4.12.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /.local/lib/python3.11/site-packages (from SQLAlchemy==2.0.36->-r requirements.txt (line 8)) (3.1.1)\n",
      "Requirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.7->matplotlib==3.9.1->-r requirements.txt (line 2)) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "361f5df92dbe8d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib created a temporary cache directory at /tmp/matplotlib-xa8u9ko9 because the default path (/.config/matplotlib) is not a writable directory; it is highly recommended to set the MPLCONFIGDIR environment variable to a writable directory, in particular to speed up the import of Matplotlib and to better support multiprocessing.\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from config import DATASET_SIZE\n",
    "from scripts.colors import bold, error, success, warning\n",
    "from scripts.utils import checkpoint, setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:16:18.213049Z",
     "start_time": "2024-12-14T17:16:17.504103Z"
    }
   },
   "outputs": [],
   "source": [
    "setup()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3142b270f6b06640",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:16:25.222023Z",
     "start_time": "2024-12-14T17:16:18.227887Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset found, reading from disk... \u001b[92mOK\u001b[0m\n",
      "Dataframe contains \u001b[1m1612409 rows\u001b[0m and \u001b[1m19 columns\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "pickle_path = \"data/filtered.pkl\"\n",
    "\n",
    "if not os.path.exists(pickle_path):\n",
    "    # Load dataset from source\n",
    "    warning(\"Local dataset not found\")\n",
    "    print(\"Reading dataset from Postgres... \", end=\"\")\n",
    "    conn = \"postgresql://postgres:adm@db:5432/adm\"\n",
    "    query = \"SELECT * FROM filtered\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    success(\"OK\")\n",
    "\n",
    "    # Cache dataset on local machine\n",
    "    print(\"Saving dataset to disk... \", end=\"\")\n",
    "    df.to_pickle(pickle_path)\n",
    "    success(\"OK\")\n",
    "else:\n",
    "    print(\"Dataset found, reading from disk... \", end=\"\")\n",
    "    # Load cached dataset\n",
    "    df = pd.read_pickle(pickle_path)\n",
    "    success(\"OK\")\n",
    "\n",
    "rows, cols = df.shape\n",
    "print(\"Dataframe contains\", bold(f\"{rows} rows\"), \"and\", bold(f\"{cols} columns\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b12764fd",
   "metadata": {},
   "source": [
    "Before doing anything, remove duplicates within the same subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7879fd15",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:16:31.944404Z",
     "start_time": "2024-12-14T17:16:25.412701Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7698 rows affected\n",
      "Dataframe contains \u001b[1m1604711 rows\u001b[0m and \u001b[1m19 columns\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "rows_count = df.shape[0]\n",
    "df = df.drop_duplicates(subset=['body', 'subreddit'])\n",
    "rows_count = rows_count - df.shape[0]\n",
    "print(rows_count, \"row\" if rows_count == 1 else \"rows\", \"affected\")\n",
    "\n",
    "rows, cols = df.shape\n",
    "print(\"Dataframe contains\", bold(f\"{rows} rows\"), \"and\", bold(f\"{cols} columns\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a90c20c5",
   "metadata": {},
   "source": [
    "Reduce dataset to several thousand samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03429525",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:16:31.955018Z",
     "start_time": "2024-12-14T17:16:31.953118Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reducing dataset to \u001b[1m20000 rows\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "print(\"Reducing dataset to\", bold(f\"{DATASET_SIZE} rows\"))  # change in config.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fdce9db",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:16:32.061860Z",
     "start_time": "2024-12-14T17:16:31.998018Z"
    }
   },
   "outputs": [],
   "source": [
    "if DATASET_SIZE <= 0:\n",
    "    error(\"Invalid dataset size\")\n",
    "\n",
    "n_classes = len(df['subreddit'].unique())\n",
    "class_size = DATASET_SIZE // n_classes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4abbc0",
   "metadata": {},
   "source": [
    "From every class, take `class_size` elements - balance dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12520ece",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:16:33.425840Z",
     "start_time": "2024-12-14T17:16:32.086325Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "subreddit\n",
      "gaming         4000\n",
      "politics       4000\n",
      "technology     4000\n",
      "science        4000\n",
      "programming    4000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Dataframe contains \u001b[1m20000 rows\u001b[0m and \u001b[1m19 columns\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "class_samples = []\n",
    "\n",
    "for subreddit in df['subreddit'].unique():\n",
    "    _df = df[df['subreddit'] == subreddit].sample(class_size)\n",
    "    class_samples.append(_df)\n",
    "\n",
    "df = pd.concat(class_samples).reset_index(drop=True)\n",
    "\n",
    "print(df['subreddit'].value_counts())\n",
    "print()\n",
    "\n",
    "rows, cols = df.shape\n",
    "print(\"Dataframe contains\", bold(f\"{rows} rows\"), \"and\", bold(f\"{cols} columns\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "225f8c33",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-14T17:16:33.565979Z",
     "start_time": "2024-12-14T17:16:33.491547Z"
    }
   },
   "outputs": [],
   "source": [
    "_ = checkpoint(\"01-balanced\", dataframe=df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
